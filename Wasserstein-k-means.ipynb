{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c09b129",
   "metadata": {
    "tags": []
   },
   "source": [
    "# K means ++ clustering of city persistence diagrams\n",
    "\n",
    "Clustering cities based on their persistence diagrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gerrychain import Graph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import gudhi\n",
    "import random\n",
    "import gudhi.hera\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "from numpy import inf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import tdaredistricting\n",
    "import geopandas as gpd\n",
    "from matplotlib.pyplot import Circle\n",
    "from tqdm import tqdm\n",
    "plt.rcParams['text.usetex'] = True\n",
    "INFINITY = 10e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('figs/clustering', exist_ok=True)\n",
    "os.makedirs('figs/MDS', exist_ok=True)\n",
    "os.makedirs('figs/pds and maps', exist_ok=True)\n",
    "os.makedirs('figs/time', exist_ok=True)\n",
    "os.makedirs('figs/TP', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd6085",
   "metadata": {},
   "source": [
    "## Globals\n",
    "\n",
    "Change these to switch between numbers of clusters, elbow plot functionality, and choice of demographic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'BLACK'\n",
    "year = 2020\n",
    "doelbow=False #set this to generate the elbow plot which can be slow\n",
    "num_clusters=5 #number of clusters for full analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69885a93",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea20ff-cab2-4a5c-a560-03fca580d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinity_is_one(PD):\n",
    "    for i, point in enumerate(PD):\n",
    "        if point[1] == inf or point[1] == INFINITY:\n",
    "            PD[i] = (PD[i][0], 1)\n",
    "    return PD\n",
    "    \n",
    "def pd_from_graph(graph1, column, popthreshold=0):\n",
    "    scomplex1 = gudhi.SimplexTree()\n",
    "    for i in graph1.nodes: \n",
    "        scomplex1.insert([i]) #add a 0-simplex, given as a list with just one vertex for (u,v) in grid.edges: \n",
    "    for (u,v) in graph1.edges:\n",
    "        scomplex1.insert([u,v]) #insert edge for v in scomplex.get_skeleton(0):\n",
    "    for v in scomplex1.get_skeleton(0):\n",
    "        node = v[0][0]\n",
    "        if graph1.nodes[node]['TOTPOP'] > popthreshold:\n",
    "            scomplex1.assign_filtration(\n",
    "                v[0],\n",
    "                filtration = 1-graph1.nodes[node][column]/graph1.nodes[node]['TOTPOP']\n",
    "            )\n",
    "        else:\n",
    "            neighbor_values = [\n",
    "                graph1.nodes[m][column]/graph1.nodes[m]['TOTPOP']\n",
    "                for m in graph1.neighbors(node) if graph1.nodes[m]['TOTPOP'] > popthreshold\n",
    "            ]\n",
    "            if len(neighbor_values) == 0:\n",
    "                scomplex1.assign_filtration(\n",
    "                    v[0],\n",
    "                    1\n",
    "                )\n",
    "            else:\n",
    "                scomplex1.assign_filtration(\n",
    "                    v[0],\n",
    "                    1-max(neighbor_values)\n",
    "                )\n",
    "    scomplex1.make_filtration_non_decreasing()\n",
    "    \n",
    "    persistence1 = scomplex1.persistence()\n",
    "    persistence01 = [x[1] for x in persistence1 if x[0] == 0]\n",
    "    for i, point in enumerate(persistence01):\n",
    "        if point[1] == inf:\n",
    "            persistence01[i] = (persistence01[i][0], INFINITY)\n",
    "    return persistence01\n",
    "\n",
    "def wasserstein_between_pds(pd1, pd2, p=1):\n",
    "    return gudhi.hera.wasserstein_distance(pd1, pd2, order = p, internal_p = p)\n",
    "\n",
    "def bottleneck_between_pds(pd1, pd2):\n",
    "    return gudhi.bottleneck_distance(pd1, pd2)\n",
    "\n",
    "  \n",
    "def total_persistence(pd1, p=1): \n",
    "    tp = np.linalg.norm(np.array([x[1]-x[0] for x in pd1]), ord=p)\n",
    "    return tp\n",
    "\n",
    "def minshare(graph1, column1):\n",
    "    total_group = sum([graph1.nodes[n][column1] for n in graph1.nodes])\n",
    "    total_population = sum([graph1.nodes[n]['TOTPOP'] for n in graph1.nodes])\n",
    "    return total_group/total_population\n",
    "\n",
    "def moransI(graph, col, pop_col='TOTPOP'):\n",
    "    A = nx.adjacency_matrix(graph).toarray()\n",
    "    P = A/A.sum(axis=0)\n",
    "    v = np.array([graph.nodes[n][col]/(graph.nodes[n][pop_col]+1e-9) for n in graph.nodes])\n",
    "    v = v-np.mean(v)\n",
    "    return np.dot(np.dot(v, P), v)/np.dot(v,v)\n",
    "\n",
    "def DI(graph, col):\n",
    "    group_pops = np.array([graph.nodes[n][col] for n in graph.nodes])\n",
    "    totpops = np.array([graph.nodes[n]['TOTPOP'] for n in graph.nodes])\n",
    "    DI = 0.5*sum(\n",
    "        np.abs(group_pops/group_pops.sum() - (totpops - group_pops)/(totpops.sum() - group_pops.sum()))\n",
    "    )\n",
    "    return DI\n",
    "\n",
    "def outliers(distance_matrix):\n",
    "    loof = np.mean(\n",
    "        [\n",
    "            LocalOutlierFactor(\n",
    "                metric='precomputed',\n",
    "                n_neighbors=k).fit(distance_matrix).negative_outlier_factor_\n",
    "            for k in range(10,20)\n",
    "        ], axis=0\n",
    "    )\n",
    "    outliers = [i for i in range(len(loof)) if loof[i] <= -2]\n",
    "    return outliers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32280e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseplusplus(M, k):\n",
    "    np.random.seed(2023)\n",
    "    seeds = [np.random.choice(range(len(M)))]\n",
    "    while len(seeds) < k:\n",
    "        x = np.random.choice(\n",
    "            range(len(M)),\n",
    "            p = M[seeds[-1]]**2/sum(M[seeds[-1]]**2)\n",
    "        )\n",
    "        seeds.append(x)\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def kmeansplusplus(PDs, k, MAXITER=100, p=2, eps=1e-5, verbose=False, seeds=None):\n",
    "    if seeds is None:\n",
    "        distances_pairwise = np.array([\n",
    "            np.array([\n",
    "                wasserstein_between_pds(pd1, pd2,p=2) for pd1 in PDs\n",
    "            ]) for pd2 in PDs\n",
    "        ])\n",
    "        M = (distances_pairwise + distances_pairwise.T)/2\n",
    "        seeds = chooseplusplus(M, k)\n",
    "    if verbose:\n",
    "        print('seeds:', seeds)\n",
    "    means = [PDs[i] for i in seeds]\n",
    "    newmeans = means.copy()\n",
    "    matches = [0]*len(PDs)\n",
    "    print('\\n')\n",
    "    for i in range(MAXITER):\n",
    "        print('.', end='')\n",
    "        #match\n",
    "        for j, PD in enumerate(PDs):\n",
    "            D = [\n",
    "                gudhi.hera.wasserstein_distance(PD, m, order = p, internal_p = p) for m in means\n",
    "            ] \n",
    "            matches[j] = np.argmin(D)\n",
    "        #average\n",
    "        for j in range(k):\n",
    "            newmeans[j] = tdaredistricting.Frechet_mean(\n",
    "                [PDs[n] for n in range(len(PDs)) if matches[n] == j],\n",
    "                seed=means[j]\n",
    "            )\n",
    "        #convergence\n",
    "        deltas = [\n",
    "            gudhi.hera.wasserstein_distance(newmeans[j], means[j], order = p, internal_p = p) for j in range(k)\n",
    "        ]\n",
    "        #track distortion\n",
    "        distortion = sum([\n",
    "            gudhi.hera.wasserstein_distance(\n",
    "                PDs[j], newmeans[matches[j]], order = p, internal_p = p\n",
    "            ) for j in range(len(PDs))\n",
    "        ])\n",
    "        if verbose:\n",
    "            print('Changes: ', deltas)\n",
    "            print('Distortion: ', distortion)\n",
    "        if max(deltas) < eps:\n",
    "            return means, matches, distortion\n",
    "        else:\n",
    "            means = newmeans.copy()\n",
    "    print('DID NOT CONVERGE')\n",
    "    return means, matches, distortion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978b0a2",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec42f0-c100-469b-9978-b498aac843fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "list_of_cities_pd =pd.read_csv('./City_Names_And_Populations.csv')\n",
    "list_of_cities = [x+y for x,y in zip(list_of_cities_pd.NAME, list_of_cities_pd.ST)][:n]\n",
    "city_names = [x+' ' + y for x,y in zip(list_of_cities_pd.NAME, list_of_cities_pd.ST)][:n]\n",
    "cmap = plt.get_cmap('tab20')\n",
    "colors = [cmap(x/(7-1)) for x in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a994b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_graphs = {'2010':[], '2020':[]}\n",
    "for year in list_of_graphs:\n",
    "    for i in range(n):\n",
    "        graph1=Graph.from_json('./cities{}data/{}.json'.format(year, list_of_cities[i]))\n",
    "#         cc = sorted(nx.connected_components(graph1), key=len, reverse=True)\n",
    "#         print(list_of_cities[i], (len(graph1) - len(cc[0]))/len(graph1))\n",
    "#         graph1 = graph1.subgraph(cc[0])\n",
    "        list_of_graphs[year].append(graph1) \n",
    "PDs = {y: [infinity_is_one(pd_from_graph(graph, col, popthreshold=10)) for graph in list_of_graphs[y]] for y in list_of_graphs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = pd.DataFrame()\n",
    "x = []\n",
    "y = []\n",
    "coords['name'] = list_of_cities[:n]\n",
    "for i, graph in enumerate(list_of_graphs['2010']):\n",
    "    node = list(graph.nodes)[0]\n",
    "    x.append(graph.nodes[node]['C_X'])\n",
    "    y.append(graph.nodes[node]['C_Y'])\n",
    "    \n",
    "coords['x'] = x\n",
    "coords['y'] = y\n",
    "coords = coords.set_index('name')\n",
    "coords.to_csv('city_coordinates.csv', index='name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d94960",
   "metadata": {},
   "source": [
    "## Do k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_pairwise = np.array([\n",
    "    np.array([\n",
    "        wasserstein_between_pds(pd1, pd2,p=2) for pd1 in PDs[year]\n",
    "    ]) for pd2 in PDs[year]\n",
    "])\n",
    "distances_pairwise = (distances_pairwise + distances_pairwise.T)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd93ef9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if doelbow:\n",
    "    elbow = []\n",
    "    for k in range(2,11):\n",
    "        np.random.seed(2023)\n",
    "        random.seed(2023)\n",
    "        means, matches, distortion = kmeansplusplus(PDs[year], k, verbose=False)\n",
    "        elbow.append(distortion)\n",
    "    print(elbow)\n",
    "    plt.plot(range(2,2+len(elbow)), elbow)\n",
    "    plt.scatter(range(2,2+len(elbow)), elbow)\n",
    "    plt.xticks(range(2+len(elbow)))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('distortion')\n",
    "    plt.savefig('figs/clustering/{}_{}_elbow_plot.png'.format(col, year), bbox_inches='tight', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "random.seed(2023)\n",
    "means, matches, distortion = kmeansplusplus(PDs['2020'], num_clusters, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2872db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder\n",
    "index_by_TP = np.argsort(\n",
    "    [\n",
    "        -sum([x[1]-x[0] for x in m]) for m in means\n",
    "    ]\n",
    ")\n",
    "reindex = {x:i for i,x in enumerate(index_by_TP)}\n",
    "matches = [reindex[m] for m in matches]\n",
    "means = [means[i] for i in index_by_TP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fipslist = ['01', '02', '04', '05', '06', '08', '09', '10', '11', '12', '13',\n",
    "            '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25',\n",
    "            '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
    "            '37', '38', '39', '40', '41', '42', '44', '45', '46', '47', '48',\n",
    "            '49', '50', '51', '53', '54', '55', '56']\n",
    "contiglist = [x for x in fipslist if x not in ['02', '15']]\n",
    "wholeUS = gpd.read_file(\n",
    "    './cb_2018_us_state_500k/cb_2018_us_state_500k.shp'\n",
    ")\n",
    "wholeUS = wholeUS.to_crs('ESRI:102003')\n",
    "contigUS = wholeUS[wholeUS.STATEFP.isin(contiglist)]\n",
    "hawaii = wholeUS[wholeUS.STATEFP == '02']\n",
    "alaska = wholeUS[wholeUS.STATEFP == '15']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "contigUS.plot(ax=ax, edgecolor='black', facecolor='white', linewidth=0.2)\n",
    "for i, graph in enumerate(list_of_graphs[year]):\n",
    "    if list_of_cities[i] not in ['HonoluluHI', 'AnchorageAK']:\n",
    "        node = list(graph.nodes)[0]\n",
    "        ax.scatter(\n",
    "            [graph.nodes[node]['C_X']],\n",
    "            [graph.nodes[node]['C_Y']],\n",
    "            s=50,\n",
    "            c=[colors[matches[i]]],\n",
    "        )\n",
    "plt.axis('off')\n",
    "plt.savefig('figs/clustering/{}_{}_US.png'.format(col, year), bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66781d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mean in enumerate(means):\n",
    "    fig, ax = plt.subplots(figsize=(2.5,2.5))\n",
    "    ax = plt.gca()\n",
    "    ax.scatter(\n",
    "        [x[0] for x in infinity_is_one(mean)],\n",
    "        [x[1] for x in infinity_is_one(mean)],\n",
    "        color=colors[i],\n",
    "        s=10\n",
    "    )\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_xticks([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_ylim(0,1.1)\n",
    "    ax.set_aspect(1)\n",
    "    ax.plot([0,1], [0,1], linestyle='dashed', c='grey')\n",
    "    ax.annotate('$\\infty$', (-0,1))\n",
    "    plt.savefig('figs/clustering/{}_{}_mean{}.png'.format(col, year, i), bbox_inches='tight', dpi=150)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cacb71",
   "metadata": {},
   "source": [
    "## Cluster stats\n",
    "\n",
    "Formatted for $\\LaTeX$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_of_city(i):\n",
    "    graph = list_of_graphs[year][i]\n",
    "    return sum(graph.nodes[n]['TOTPOP'] for n in graph.nodes)\n",
    "\n",
    "print('cluster & \\\\#cities & ave. pop & ave. \\\\# tracts & ave. \\% {} \\\\\\ '.format(col))\n",
    "for k in range(len(means)):\n",
    "    indexesofPDs = [j for j in range(len(PDs[year])) if matches[j] == k]\n",
    "    thesePDs = [PDs[year][j] for j in indexesofPDs]\n",
    "    print('{} \\\\textcolor {{mycolor{}}}{{$\\\\blacksquare$}}'.format(k+1, k+1), end=' & ')\n",
    "    print(len(thesePDs), end=' & ')\n",
    "    print('{:.2f} '.format(np.mean([pop_of_city(i) for i in indexesofPDs])), end=' & ')\n",
    "    print('{:.2f} '.format(np.mean([len(list_of_graphs[year][i]) for i in indexesofPDs])), end=' & ')\n",
    "    print('{:.2f} \\% \\\\\\ '.format(100*np.mean([minshare(list_of_graphs[year][i], col) for i in indexesofPDs])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
